{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50000 entries...\n",
      "Processed 100000 entries...\n",
      "Processed 150000 entries...\n",
      "Processed 200000 entries...\n",
      "Processed 250000 entries...\n",
      "Processed 300000 entries...\n",
      "Processed 350000 entries...\n",
      "Processed 400000 entries...\n",
      "Processed 450000 entries...\n",
      "Processed 500000 entries...\n",
      "Processed 550000 entries...\n",
      "Processed 600000 entries...\n",
      "Processed 650000 entries...\n",
      "Processed 700000 entries...\n",
      "Processed 750000 entries...\n",
      "Processed 800000 entries...\n",
      "Processed 850000 entries...\n",
      "Processed 900000 entries...\n",
      "Processed 950000 entries...\n",
      "Processed 1000000 entries...\n",
      "Processed 1050000 entries...\n",
      "Processed 1100000 entries...\n",
      "Processed 1150000 entries...\n",
      "Processed 1200000 entries...\n",
      "Processed 1250000 entries...\n",
      "Processed 1300000 entries...\n",
      "Processed 1350000 entries...\n",
      "Processed 1400000 entries...\n",
      "Processed 1450000 entries...\n",
      "Processed 1500000 entries...\n",
      "Processed 1550000 entries...\n",
      "Processed 1600000 entries...\n",
      "Processed 1650000 entries...\n",
      "Processed 1700000 entries...\n",
      "Processed 1750000 entries...\n",
      "Processed 1800000 entries...\n",
      "Processed 1850000 entries...\n",
      "Processed 1900000 entries...\n",
      "Processed 1950000 entries...\n",
      "Processed 2000000 entries...\n",
      "Processed 2050000 entries...\n",
      "Processed 2100000 entries...\n",
      "Processed 2150000 entries...\n",
      "Processed 2200000 entries...\n",
      "Preprocessed 2231142 recipes and saved to ./data/preprocessed_recipes.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def preprocess_recipes_from_csv(input_csv, output_file):\n",
    "    \"\"\"\n",
    "    Preprocesses the Recipe1M+ dataset from a CSV file into instruction-response format.\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Path to the raw Recipe1M+ dataset file (CSV format).\n",
    "        output_file (str): Path to save the preprocessed dataset in instruction-response format.\n",
    "    \"\"\"\n",
    "    preprocessed_data = []\n",
    "    counter = 0  # Initialize a counter\n",
    "    \n",
    "    # Open and read the CSV file\n",
    "    with open(input_csv, 'r') as infile:\n",
    "        csv_reader = csv.DictReader(infile)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            counter += 1  # Increment the counter\n",
    "            \n",
    "            # Extract relevant fields\n",
    "            title = row.get('title', '').strip()\n",
    "            ingredients = row.get('ingredients', '').strip()\n",
    "            directions = row.get('directions', '').strip()\n",
    "            \n",
    "            # Skip recipes with missing fields\n",
    "            if not title or not ingredients or not directions:\n",
    "                continue\n",
    "            \n",
    "            # Split ingredients into a list and reformat as bullet points\n",
    "            ingredients_list = \"\\n\".join([f\"- {ing.strip()}\" for ing in ingredients.split('|') if ing.strip()])\n",
    "            \n",
    "            # Split directions into numbered steps\n",
    "            directions_list = \"\\n\".join([f\"{i + 1}. {step.strip()}\" for i, step in enumerate(directions.split('|')) if step.strip()])\n",
    "            \n",
    "            # Skip if directions are empty after processing\n",
    "            if not directions_list:\n",
    "                continue\n",
    "            \n",
    "            # Create instruction and response\n",
    "            instruction = f\"Write a recipe containing the following ingredients only:\\n{ingredients_list}\"\n",
    "            response = f\"<recipe>\\n<title> {title} </title>\\n<ingredients>\\n{ingredients_list}\\n</ingredients>\\n<directions>\\n{directions_list}\\n</directions>\\n</recipe>\"\n",
    "            \n",
    "            # Append to preprocessed data\n",
    "            preprocessed_data.append({\n",
    "                \"instruction\": instruction,\n",
    "                \"response\": response\n",
    "            })\n",
    "            \n",
    "            # Print a progress message every 50,000 entries processed\n",
    "            if counter % 50000 == 0:\n",
    "                print(f\"Processed {counter} entries...\")\n",
    "    \n",
    "    # Save the preprocessed data to a JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(preprocessed_data, outfile, indent=4)\n",
    "\n",
    "    print(f\"Preprocessed {len(preprocessed_data)} recipes and saved to {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "# Replace 'recipe1m_raw.csv' with the actual path to your Recipe1M+ dataset in CSV format\n",
    "input_csv_path = './data/dataset/full_dataset.csv'\n",
    "output_json_path = './data/preprocessed_recipes.json'\n",
    "preprocess_recipes_from_csv(input_csv_path, output_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
